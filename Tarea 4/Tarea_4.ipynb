{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "urj8WfyEBe3j"
      },
      "source": [
        "#IIC-2433 Minería de Datos UC\n",
        "\n",
        "* Versiones de librerías, python 3.8.10\n",
        "* pandas 1.5.3\n",
        "* tensorflow/keras 2.12.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Flatten\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KpscHAvkDcmh"
      },
      "source": [
        "# 1. Carga de la base de datos"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "luvxU_uaY6sL"
      },
      "source": [
        "En esta tarea se trabajará con un dataset de vinos obtenido de Kaggle:\n",
        "Cárguelo, léalo y muéstrelo.\n",
        "\n",
        "https://www.kaggle.com/datasets/yasserh/wine-quality-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "y6vYAYIV4yKQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1143, 13)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dframe = pd.read_csv(\"WineQT.csv\", encoding = \"ISO-8859-1\")\n",
        "dframe.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.880</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.99700</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1138</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.510</td>\n",
              "      <td>0.13</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.076</td>\n",
              "      <td>29.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.99574</td>\n",
              "      <td>3.42</td>\n",
              "      <td>0.75</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6</td>\n",
              "      <td>1592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1139</th>\n",
              "      <td>6.8</td>\n",
              "      <td>0.620</td>\n",
              "      <td>0.08</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.068</td>\n",
              "      <td>28.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.99651</td>\n",
              "      <td>3.42</td>\n",
              "      <td>0.82</td>\n",
              "      <td>9.5</td>\n",
              "      <td>6</td>\n",
              "      <td>1593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1140</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.08</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.090</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.45</td>\n",
              "      <td>0.58</td>\n",
              "      <td>10.5</td>\n",
              "      <td>5</td>\n",
              "      <td>1594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1141</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.10</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.062</td>\n",
              "      <td>39.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.99512</td>\n",
              "      <td>3.52</td>\n",
              "      <td>0.76</td>\n",
              "      <td>11.2</td>\n",
              "      <td>6</td>\n",
              "      <td>1595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1142</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.645</td>\n",
              "      <td>0.12</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.075</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99547</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.71</td>\n",
              "      <td>10.2</td>\n",
              "      <td>5</td>\n",
              "      <td>1597</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1143 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0               7.4             0.700         0.00             1.9      0.076   \n",
              "1               7.8             0.880         0.00             2.6      0.098   \n",
              "2               7.8             0.760         0.04             2.3      0.092   \n",
              "3              11.2             0.280         0.56             1.9      0.075   \n",
              "4               7.4             0.700         0.00             1.9      0.076   \n",
              "...             ...               ...          ...             ...        ...   \n",
              "1138            6.3             0.510         0.13             2.3      0.076   \n",
              "1139            6.8             0.620         0.08             1.9      0.068   \n",
              "1140            6.2             0.600         0.08             2.0      0.090   \n",
              "1141            5.9             0.550         0.10             2.2      0.062   \n",
              "1142            5.9             0.645         0.12             2.0      0.075   \n",
              "\n",
              "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
              "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
              "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
              "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
              "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
              "...                   ...                   ...      ...   ...        ...   \n",
              "1138                 29.0                  40.0  0.99574  3.42       0.75   \n",
              "1139                 28.0                  38.0  0.99651  3.42       0.82   \n",
              "1140                 32.0                  44.0  0.99490  3.45       0.58   \n",
              "1141                 39.0                  51.0  0.99512  3.52       0.76   \n",
              "1142                 32.0                  44.0  0.99547  3.57       0.71   \n",
              "\n",
              "      alcohol  quality    Id  \n",
              "0         9.4        5     0  \n",
              "1         9.8        5     1  \n",
              "2         9.8        5     2  \n",
              "3         9.8        6     3  \n",
              "4         9.4        5     4  \n",
              "...       ...      ...   ...  \n",
              "1138     11.0        6  1592  \n",
              "1139      9.5        6  1593  \n",
              "1140     10.5        5  1594  \n",
              "1141     11.2        6  1595  \n",
              "1142     10.2        5  1597  \n",
              "\n",
              "[1143 rows x 13 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dframe"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dgyQ3wpeC4QS"
      },
      "source": [
        "# 2. Preprocesamiento"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Cb4_ZpC7E_"
      },
      "source": [
        "Realice el preprocesamiento que considere adecuado para este *dataset* y argumente todas sus decisiones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Astqo3Pb4vvZ"
      },
      "outputs": [],
      "source": [
        " #Chequeamos si hay algun valor nulo en el df, y si hay eliminamos la fila\n",
        "if dframe.isnull().values.any():\n",
        "    dframe.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.880</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.99700</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1138</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.510</td>\n",
              "      <td>0.13</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.076</td>\n",
              "      <td>29.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.99574</td>\n",
              "      <td>3.42</td>\n",
              "      <td>0.75</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6</td>\n",
              "      <td>1592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1139</th>\n",
              "      <td>6.8</td>\n",
              "      <td>0.620</td>\n",
              "      <td>0.08</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.068</td>\n",
              "      <td>28.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.99651</td>\n",
              "      <td>3.42</td>\n",
              "      <td>0.82</td>\n",
              "      <td>9.5</td>\n",
              "      <td>6</td>\n",
              "      <td>1593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1140</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.08</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.090</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.45</td>\n",
              "      <td>0.58</td>\n",
              "      <td>10.5</td>\n",
              "      <td>5</td>\n",
              "      <td>1594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1141</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.10</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.062</td>\n",
              "      <td>39.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.99512</td>\n",
              "      <td>3.52</td>\n",
              "      <td>0.76</td>\n",
              "      <td>11.2</td>\n",
              "      <td>6</td>\n",
              "      <td>1595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1142</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.645</td>\n",
              "      <td>0.12</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.075</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99547</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.71</td>\n",
              "      <td>10.2</td>\n",
              "      <td>5</td>\n",
              "      <td>1597</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>834 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0               7.4             0.700         0.00             1.9      0.076   \n",
              "1               7.8             0.880         0.00             2.6      0.098   \n",
              "2               7.8             0.760         0.04             2.3      0.092   \n",
              "3              11.2             0.280         0.56             1.9      0.075   \n",
              "4               7.4             0.700         0.00             1.9      0.076   \n",
              "...             ...               ...          ...             ...        ...   \n",
              "1138            6.3             0.510         0.13             2.3      0.076   \n",
              "1139            6.8             0.620         0.08             1.9      0.068   \n",
              "1140            6.2             0.600         0.08             2.0      0.090   \n",
              "1141            5.9             0.550         0.10             2.2      0.062   \n",
              "1142            5.9             0.645         0.12             2.0      0.075   \n",
              "\n",
              "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
              "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
              "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
              "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
              "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
              "...                   ...                   ...      ...   ...        ...   \n",
              "1138                 29.0                  40.0  0.99574  3.42       0.75   \n",
              "1139                 28.0                  38.0  0.99651  3.42       0.82   \n",
              "1140                 32.0                  44.0  0.99490  3.45       0.58   \n",
              "1141                 39.0                  51.0  0.99512  3.52       0.76   \n",
              "1142                 32.0                  44.0  0.99547  3.57       0.71   \n",
              "\n",
              "      alcohol  quality    Id  \n",
              "0         9.4        5     0  \n",
              "1         9.8        5     1  \n",
              "2         9.8        5     2  \n",
              "3         9.8        6     3  \n",
              "4         9.4        5     4  \n",
              "...       ...      ...   ...  \n",
              "1138     11.0        6  1592  \n",
              "1139      9.5        6  1593  \n",
              "1140     10.5        5  1594  \n",
              "1141     11.2        6  1595  \n",
              "1142     10.2        5  1597  \n",
              "\n",
              "[834 rows x 13 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calcular el rango intercuartílico\n",
        "Q1 = dframe.quantile(0.25)\n",
        "Q3 = dframe.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Definir los límites inferior y superior para detectar outliers\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Filtrar los outliers\n",
        "filtered_df = dframe[~((dframe < lower_bound) | (dframe > upper_bound)).any(axis=1)]\n",
        "filtered_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prediceremos Quality\n",
        "X = filtered_df.drop('quality', axis=1)\n",
        "y = filtered_df['quality']\n",
        "y = to_categorical(y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_7GwwQOGD3C_"
      },
      "source": [
        "# 3. Preguntas iniciales\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dS5e6dUNEi_6"
      },
      "source": [
        "Deberá encontrar la mejor combinación de hiperparámetros que le permita obtener el modelo con mejor *accuracy*.\n",
        "\n",
        "A priori, ¿cuáles cree que serán las mejores combinaciones de hiperparámetros para este problema en particular? ¿Por qué?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Un patience alto puede ayudar a obtener un mejor modelo, dado que define cuantos epochs consecutivos pueden haber sin mejora, pero si despues logra \"desestancarse\" seguira mejorando \n",
        "- un alto numero de epochs combinado con el parametro que dije antes.\n",
        "- El numero de capas neuronales para aumentar la complejidad del modelo (aunque a su vez afecta su velocidad y uso de recursos)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UO8VTsHi13o9"
      },
      "source": [
        "# 3. Modelos"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QsPcsGib3hxc"
      },
      "source": [
        "Ocupando la librería **keras** de tensorflow, construya redes neuronales multicapas variando los siguientes hiperparámetros: función de activación, cantidad de neuronas por cada capa, cantidad de capas, optimizador y cantidad de épocas."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### INTENTO 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_y8RXf8v4tHC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "17/17 [==============================] - 1s 8ms/step - loss: 2.0105 - accuracy: 0.1839 - val_loss: 1.8247 - val_accuracy: 0.4254\n",
            "Epoch 2/300\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 1.6849 - accuracy: 0.4747 - val_loss: 1.4342 - val_accuracy: 0.4701\n",
            "Epoch 3/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 1.2890 - accuracy: 0.5159 - val_loss: 1.0897 - val_accuracy: 0.5522\n",
            "Epoch 4/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 1.0531 - accuracy: 0.5797 - val_loss: 0.9379 - val_accuracy: 0.5672\n",
            "Epoch 5/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.9493 - accuracy: 0.6079 - val_loss: 0.8813 - val_accuracy: 0.5821\n",
            "Epoch 6/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.8967 - accuracy: 0.6229 - val_loss: 0.8630 - val_accuracy: 0.6119\n",
            "Epoch 7/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.8622 - accuracy: 0.6323 - val_loss: 0.8585 - val_accuracy: 0.6194\n",
            "Epoch 8/300\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.8440 - accuracy: 0.6341 - val_loss: 0.8559 - val_accuracy: 0.6269\n",
            "Epoch 9/300\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.8166 - accuracy: 0.6248 - val_loss: 0.8555 - val_accuracy: 0.6194\n",
            "Epoch 10/300\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.7955 - accuracy: 0.6492 - val_loss: 0.8579 - val_accuracy: 0.6269\n",
            "Epoch 11/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.7832 - accuracy: 0.6529 - val_loss: 0.8581 - val_accuracy: 0.6119\n",
            "Epoch 12/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.7661 - accuracy: 0.6679 - val_loss: 0.8535 - val_accuracy: 0.6119\n",
            "Epoch 13/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.7572 - accuracy: 0.6660 - val_loss: 0.8630 - val_accuracy: 0.6269\n",
            "Epoch 14/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.7447 - accuracy: 0.6642 - val_loss: 0.8599 - val_accuracy: 0.6194\n",
            "Epoch 15/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.7318 - accuracy: 0.6811 - val_loss: 0.8689 - val_accuracy: 0.6194\n",
            "21/21 [==============================] - 0s 700us/step\n",
            "6/6 [==============================] - 0s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=3)]\n",
        "\n",
        "model.fit(X_train, y_train, validation_split=0.2, epochs=300, callbacks=callbacks)\n",
        "\n",
        "y_train_pred = np.argmax(model.predict(X_train), axis=-1)\n",
        "y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "\n",
        "y_train_label = np.argmax(y_train, axis=-1)\n",
        "y_test_label = np.argmax(y_test, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy:  0.6701649175412294\n",
            "\n",
            "Train Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           4       0.00      0.00      0.00        17\n",
            "           5       0.67      0.82      0.74       297\n",
            "           6       0.67      0.59      0.62       280\n",
            "           7       0.66      0.55      0.60        73\n",
            "\n",
            "    accuracy                           0.67       667\n",
            "   macro avg       0.50      0.49      0.49       667\n",
            "weighted avg       0.65      0.67      0.66       667\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Train Accuracy: \", accuracy_score(y_train_label, y_train_pred))\n",
        "\n",
        "print(\"\\nTrain Classification Report:\")\n",
        "print(classification_report(y_train_label, y_train_pred,zero_division=0))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lo logre altiro xd"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### INTENTO 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "15/15 [==============================] - 1s 10ms/step - loss: 2.0822 - accuracy: 0.0730 - val_loss: 1.9496 - val_accuracy: 0.2991\n",
            "Epoch 2/20\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 1.8630 - accuracy: 0.3734 - val_loss: 1.6951 - val_accuracy: 0.5470\n",
            "Epoch 3/20\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 1.5957 - accuracy: 0.5107 - val_loss: 1.3621 - val_accuracy: 0.5897\n",
            "Epoch 4/20\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 1.3202 - accuracy: 0.5773 - val_loss: 1.1717 - val_accuracy: 0.5641\n",
            "Epoch 5/20\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 1.1738 - accuracy: 0.5901 - val_loss: 1.0953 - val_accuracy: 0.5897\n",
            "Epoch 6/20\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 1.0701 - accuracy: 0.6116 - val_loss: 1.0448 - val_accuracy: 0.6239\n",
            "Epoch 7/20\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.9588 - accuracy: 0.6373 - val_loss: 0.9876 - val_accuracy: 0.6154\n",
            "Epoch 8/20\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.8778 - accuracy: 0.6459 - val_loss: 0.9460 - val_accuracy: 0.6068\n",
            "Epoch 9/20\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.8286 - accuracy: 0.6588 - val_loss: 0.9283 - val_accuracy: 0.5726\n",
            "Epoch 10/20\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.7947 - accuracy: 0.6674 - val_loss: 0.9067 - val_accuracy: 0.6239\n",
            "Epoch 11/20\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.7789 - accuracy: 0.6609 - val_loss: 0.9017 - val_accuracy: 0.6068\n",
            "Epoch 12/20\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.7614 - accuracy: 0.6803 - val_loss: 0.9189 - val_accuracy: 0.5897\n",
            "Epoch 13/20\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.7299 - accuracy: 0.6931 - val_loss: 0.9091 - val_accuracy: 0.5812\n",
            "Epoch 14/20\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.7142 - accuracy: 0.6996 - val_loss: 0.9008 - val_accuracy: 0.5812\n",
            "Epoch 15/20\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.7210 - val_loss: 0.9207 - val_accuracy: 0.5641\n",
            "Epoch 16/20\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6784 - accuracy: 0.7146 - val_loss: 0.9193 - val_accuracy: 0.5983\n",
            "Epoch 17/20\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6643 - accuracy: 0.7167 - val_loss: 0.9323 - val_accuracy: 0.5812\n",
            "Epoch 18/20\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.7232 - val_loss: 0.9141 - val_accuracy: 0.5641\n",
            "Epoch 19/20\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6288 - accuracy: 0.7296 - val_loss: 0.9024 - val_accuracy: 0.5897\n",
            "19/19 [==============================] - 0s 722us/step\n",
            "8/8 [==============================] - 0s 714us/step\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=5)]\n",
        "\n",
        "model.fit(X_train, y_train, validation_split=0.2, epochs=20, callbacks=callbacks)\n",
        "\n",
        "y_train_pred = np.argmax(model.predict(X_train), axis=-1)\n",
        "y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "\n",
        "y_train_label = np.argmax(y_train, axis=-1)\n",
        "y_test_label = np.argmax(y_test, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy:  0.7204116638078902\n",
            "\n",
            "Train Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           4       0.00      0.00      0.00        14\n",
            "           5       0.72      0.83      0.77       261\n",
            "           6       0.70      0.66      0.68       241\n",
            "           7       0.81      0.64      0.72        67\n",
            "\n",
            "    accuracy                           0.72       583\n",
            "   macro avg       0.56      0.53      0.54       583\n",
            "weighted avg       0.71      0.72      0.71       583\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Train Accuracy: \", accuracy_score(y_train_label, y_train_pred))\n",
        "\n",
        "print(\"\\nTrain Classification Report:\")\n",
        "print(classification_report(y_train_label, y_train_pred,zero_division=0))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### INTENTO 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "15/15 [==============================] - 1s 10ms/step - loss: 1.9554 - accuracy: 0.3026 - val_loss: 1.8135 - val_accuracy: 0.4188\n",
            "Epoch 2/40\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 1.7275 - accuracy: 0.4571 - val_loss: 1.6137 - val_accuracy: 0.4188\n",
            "Epoch 3/40\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 1.5008 - accuracy: 0.4592 - val_loss: 1.3765 - val_accuracy: 0.4615\n",
            "Epoch 4/40\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 1.2748 - accuracy: 0.5236 - val_loss: 1.1411 - val_accuracy: 0.5556\n",
            "Epoch 5/40\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 1.1023 - accuracy: 0.5794 - val_loss: 1.0280 - val_accuracy: 0.5641\n",
            "Epoch 6/40\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 1.0276 - accuracy: 0.6180 - val_loss: 0.9839 - val_accuracy: 0.5812\n",
            "Epoch 7/40\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.9820 - accuracy: 0.6245 - val_loss: 0.9710 - val_accuracy: 0.5641\n",
            "Epoch 8/40\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.9444 - accuracy: 0.6309 - val_loss: 0.9659 - val_accuracy: 0.5470\n",
            "Epoch 9/40\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.9135 - accuracy: 0.6373 - val_loss: 0.9479 - val_accuracy: 0.5556\n",
            "Epoch 10/40\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.8890 - accuracy: 0.6373 - val_loss: 0.9394 - val_accuracy: 0.5556\n",
            "Epoch 11/40\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.8656 - accuracy: 0.6416 - val_loss: 0.9262 - val_accuracy: 0.5556\n",
            "Epoch 12/40\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.8417 - accuracy: 0.6373 - val_loss: 0.9162 - val_accuracy: 0.5641\n",
            "Epoch 13/40\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.8199 - accuracy: 0.6524 - val_loss: 0.9052 - val_accuracy: 0.5726\n",
            "Epoch 14/40\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.8035 - accuracy: 0.6567 - val_loss: 0.9009 - val_accuracy: 0.5641\n",
            "Epoch 15/40\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.7884 - accuracy: 0.6609 - val_loss: 0.8941 - val_accuracy: 0.5897\n",
            "Epoch 16/40\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.7720 - accuracy: 0.6760 - val_loss: 0.8935 - val_accuracy: 0.5812\n",
            "Epoch 17/40\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.7598 - accuracy: 0.6867 - val_loss: 0.8869 - val_accuracy: 0.5983\n",
            "Epoch 18/40\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7448 - accuracy: 0.6824 - val_loss: 0.8863 - val_accuracy: 0.6154\n",
            "Epoch 19/40\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.6824 - val_loss: 0.8883 - val_accuracy: 0.5897\n",
            "Epoch 20/40\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.7235 - accuracy: 0.7017 - val_loss: 0.8804 - val_accuracy: 0.6068\n",
            "Epoch 21/40\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.7138 - accuracy: 0.7017 - val_loss: 0.8850 - val_accuracy: 0.6068\n",
            "Epoch 22/40\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.7023 - accuracy: 0.7039 - val_loss: 0.8836 - val_accuracy: 0.5983\n",
            "Epoch 23/40\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6955 - accuracy: 0.7124 - val_loss: 0.8895 - val_accuracy: 0.6068\n",
            "Epoch 24/40\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6838 - accuracy: 0.7103 - val_loss: 0.8874 - val_accuracy: 0.5726\n",
            "Epoch 25/40\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6763 - accuracy: 0.7017 - val_loss: 0.8958 - val_accuracy: 0.6154\n",
            "Epoch 26/40\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6687 - accuracy: 0.7082 - val_loss: 0.8958 - val_accuracy: 0.5983\n",
            "Epoch 27/40\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6602 - accuracy: 0.7189 - val_loss: 0.9132 - val_accuracy: 0.5812\n",
            "Epoch 28/40\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.7210 - val_loss: 0.9041 - val_accuracy: 0.5897\n",
            "Epoch 29/40\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6412 - accuracy: 0.7189 - val_loss: 0.9120 - val_accuracy: 0.5897\n",
            "Epoch 30/40\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.7339 - val_loss: 0.9143 - val_accuracy: 0.5983\n",
            "19/19 [==============================] - 0s 611us/step\n",
            "8/8 [==============================] - 0s 572us/step\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
        "\n",
        "model.fit(X_train, y_train, validation_split=0.2, epochs=40, callbacks=callbacks)\n",
        "\n",
        "y_train_pred = np.argmax(model.predict(X_train), axis=-1)\n",
        "y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "\n",
        "y_train_label = np.argmax(y_train, axis=-1)\n",
        "y_test_label = np.argmax(y_test, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy:  0.7135506003430532\n",
            "\n",
            "Train Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           4       0.00      0.00      0.00        14\n",
            "           5       0.71      0.84      0.77       261\n",
            "           6       0.72      0.64      0.68       241\n",
            "           7       0.70      0.63      0.66        67\n",
            "\n",
            "    accuracy                           0.71       583\n",
            "   macro avg       0.53      0.53      0.53       583\n",
            "weighted avg       0.70      0.71      0.70       583\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Train Accuracy: \", accuracy_score(y_train_label, y_train_pred))\n",
        "\n",
        "print(\"\\nTrain Classification Report:\")\n",
        "print(classification_report(y_train_label, y_train_pred,zero_division=0))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Intente encontrar un modelo que obtenga un 66.6% de *accuracy*. ¿Lo logró? ¿por qué?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se logro, "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hSvcEphO4ccy"
      },
      "source": [
        "Una vez obtenido el mejor clasificador, ¿cuáles son sus errores más comunes? ¿cómo se podrían mejorar?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MvdM6uNb1-Gs"
      },
      "source": [
        "# 4. Preguntas finales"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlNhCmU32e5t"
      },
      "source": [
        "¿Qué resultados obtuvo? Se habrá dado cuenta que encontrar el mejor modelo no es lo mismo que buscar los mejores hiperparámetros unilateralmente. ¿Cuáles combinaciones funcionaron mejor y cuáles peor? ¿Por qué cree que fue así? Argumente."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "uUosnZZmhT2i"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
