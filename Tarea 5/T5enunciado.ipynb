{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pontificia Universidad Católica de Chile <br>\n",
    "Departamento de Ciencia de la Computación <br>\n",
    "IIC2433 - Minería de Datos\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "    <h2> Tarea 5 </h2>\n",
    "    <h1> Ensembles </h1>\n",
    "    <p>\n",
    "        Profesor Marcelo Mendoza<br>\n",
    "        Primer Semestre 2023<br>    \n",
    "        Fecha de entrega: Miércoles  8 de Junio\n",
    "    </p>\n",
    "    <br>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicaciones\n",
    "\n",
    "Deberás entregar **SOLO** el archivo .ipynb en el buzón respectivo en canvas. \n",
    "\n",
    "**IMPORTANTE**: \n",
    "- Se te dará puntaje tanto por código como por la manera en la que respondas las preguntas planteadas. Es decir, si tienes un código perfecto pero este no es explicado o no se responden preguntas asociadas a este, no se tendrá el puntaje completo.\n",
    "- El notebook debe tener todas las celdas de código ejecutadas. Cualquier notebook que no las tenga no podrá ser corregido.\n",
    "- El carácter de esta tarea es **INDIVIDUAL**. Cualquier instancia de copia resultará en un 1,1 como nota de curso.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Carga de datos\n",
    "En esta tarea debes usar el dataset de Titanic que puedes descargar desde [Kaggle](https://www.kaggle.com/competitions/titanic/data?select=train.csv), solo necesitas el archivo `train.csv`.\n",
    "\n",
    "Describe el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Preprocesamiento (15 ptos.)\n",
    "Primero debes separar los datos en conjuntos de training y test (70/30).\n",
    "\n",
    "Luego, es necesario preprocesar los datos, por lo que debes considerar si es necesario hacer entre otras, las siguientes cosas:\n",
    "- Remover columnas\n",
    "- Normalizar variables\n",
    "- Manejo de valores nulos\n",
    "\n",
    "En este caso se necesita hacer un paso de preprocesamiento particular. Para manejar los datos categoricos tienes que usar One Hot Encoding.\n",
    "\n",
    "Recuerda justificar cada paso de preprocesamiento que hagas.\n",
    "\n",
    "### Preguntas:\n",
    "- ¿Por que es necesario usar One Hot Encoding?¿Cuál es el problema con usar numeros enteros para codificar las categorias?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: Decision Tree (15 ptos.)\n",
    "Entrena un Decision Tree y ajusta el parametro que controla la profundidad máxima del árbol, luego reporta las métricas vistas en el curso en los datos de testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4: Ensembles (30 ptos.)\n",
    "Entrena los modelos Random Forest y AdaBoost, cada uno usando 50, 100 y 150 Decision Trees. Computa las métricas vistas en el curso y luego graficalas en el eje Y y la cantidad de árboles en el eje X. Compara los resultados con los obtenido en la parte 3.\n",
    "\n",
    "Luego, ajusta la cantidad de árboles para cada uno de los ensembles, para esto apoyate de un gráfico error vs número de arboles.\n",
    "\n",
    "### Preguntas:\n",
    "- Explica en alto nivel, pero de forma completa cómo funcionan cada uno de los algoritmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
